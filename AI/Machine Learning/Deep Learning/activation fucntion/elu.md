# 에?루

1. 개념

   ELU(Exponential Linear Unit)는 입력값이 음수일 때 함수가 스무스하게 0에 가까운 값으로 수렴하는 활성화 함수이다. 이는 ReLU와 달리 음수 입력값에 대해 작은 음수 출력을 생성하여 뉴런이 죽는 현상을 방지한다. 수식으로는 다음과 같이 표현할 수 있다.

   입력값이 양수이면 그대로 출력하고,

   > $E(x) = x$

   음수이면 입력값에 대해 지수함수를 적용하여 출력한다.

   > $E(x) =α (exp(x) - 1)$

   여기서 α는 양수의 하이퍼파라미터로, 일반적으로 1로 설정된다.

2. 특징

   ELU는 학습이 안정적으로 이루어지고 gradient vanishing(기울기 소실) 문제를 완화할 수 있다는 장점이 있다. 이는 음수 입력값에 대해 작은 음수 출력을 생성함으로써, 뉴런이 죽는 현상을 방지하고, 네트워크의 표현력을 높여준다. 하지만 exponential 함수를 사용하므로 계산이 느린 편이다. 특히, 하드웨어 가속기(GPU)에서 ReLU에 비해 계산 비용이 더 많이 소요될 수 있다. 그럼에도 불구하고, ELU는 많은 경우에서 더 나은 성능을 보일 수 있다.
